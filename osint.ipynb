{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichalMSlusarski/Basic-sentiment-analysis/blob/main/osint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"OSINT-2.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Rozpoznawanie głosu\n",
        "# Na podstawie: E. Tsukerman: Machine Learning for Cybersecurity Cookbook. Packt Publishing 2019.\n",
        "# Pliki do wykorzystania: https://commons.wikimedia.org/wiki/Category:BBC_voice_samples\n",
        "\n",
        "!pip install speechrecognition\n",
        "\n",
        "import speech_recognition\n",
        "\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "file = (\"aung.flac\", \"cooper.flac\", \"massey.flac\")\n",
        "\n",
        "keywords = [\"person\", \"world\", \"usa\", \"freedom\", \"Cinema\", \"Kubrick\"]\n",
        "\n",
        "#Definiuje funkcję, która używa Google speech API do konwersji plik audio na tekst.\n",
        "\n",
        "def transcribe_audio_file_to_text(audio_file):\n",
        "    recognizer = speech_recognition.Recognizer()\n",
        "    with speech_recognition.AudioFile(audio_file) as audio_source:\n",
        "        audio = recognizer.record(audio_source)\n",
        "        return recognizer.recognize_google(audio)\n",
        "\n",
        "# Przetwarza plik dźwiękowy na tekst i tworzy słownik wskazujący lokalizację tekstu.\n",
        "audio_corpus = {}\n",
        "for audio_file in file:\n",
        "  audio_corpus[transcribe_audio_file_to_text(audio_file)] = audio_file\n",
        "print(audio_corpus)\n",
        "\n",
        "# Identyfikuje zdefiniowane wcześniej słowa kluczowe w przekonwertowanym pliku.\n",
        "for keyword in keywords:\n",
        "    for transcription in audio_corpus:\n",
        "        if keyword in transcription:\n",
        "            print(\n",
        "                \"keyword \"\n",
        "                + keyword\n",
        "                + \" found in audio \"\n",
        "                + '\"'\n",
        "                + audio_corpus[transcription]\n",
        "                + '\"'\n",
        "            )"
      ],
      "metadata": {
        "id": "hdiERvWVHdJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"OSINT-5.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Podobieństwo dokumentów. \n",
        "# Na podstawie: P. Deitel, H. Deitel: Python dla programistów. Gliwice 2020.\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "# Podobieństwo wg Spacy\n",
        "\n",
        "with open('sr_aug_trans.txt') as f:\n",
        "    hamlet = f.read()\n",
        "\n",
        "with open('assembly_ai_aug_trans.txt') as f:\n",
        "    makbet = f.read()\n",
        "\n",
        "doc1 = nlp(makbet)\n",
        "\n",
        "doc2 = nlp(hamlet)\n",
        "\n",
        "doc1.similarity(doc2)\n",
        "\n",
        "token1 = set(hamlet.split())\n",
        "token2 = set(makbet.split())\n",
        "\n",
        "def jaccard_similarity(token1, token2):\n",
        "  nominator = token1.intersection(token2)\n",
        "  denominator = token1.union(token2)\n",
        "  similarity = len(nominator)/len(denominator)\n",
        "  return(similarity)\n",
        "\n",
        "similarity = jaccard_similarity(token1, token2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "id": "ypGQLpboJwBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"OSINT-3.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#Rozpoznawanie mowy. Na podstawie: https://towardsdatascience.com/a-step-by-step-guide-to-summarizing-audio-files-in-python-55059bec54a7\n",
        "# Pliki do wykorzystania: https://commons.wikimedia.org/wiki/Category:BBC_voice_samples\n",
        "\n",
        "from google.colab import files\n",
        "uploaded=files.upload()\n",
        "\n",
        "file = (\"aung.flac\")\n",
        "\n",
        "import requests\n",
        "import json\n",
        "from time import sleep\n",
        "\n",
        "# Wymaga klucza API - https://www.assemblyai.com/\n",
        "API_key = \"21fd77bc01dd4dc6bde0f0e051ac206e\" \n",
        "\n",
        "headers = headers = {\n",
        "    'authorization': API_key, \n",
        "    'content-type': 'application/json',\n",
        "}\n",
        "\n",
        "upload_endpoint = 'https://api.assemblyai.com/v2/upload'\n",
        "transcription_endpoint = \"https://api.assemblyai.com/v2/transcript\"\n",
        "\n",
        "# Funkcja definiująca wgrywanie plików audio na servery Assembly\n",
        "def upload(file):\n",
        "\n",
        "    def read_audio(file):\n",
        "\n",
        "        with open(file, 'rb') as f:\n",
        "            while True:\n",
        "                data = f.read(5_242_880)\n",
        "                if not data:\n",
        "                    break\n",
        "                yield data\n",
        "\n",
        "    upload_response =  requests.post(upload_endpoint, \n",
        "                                     headers=headers, \n",
        "                                     data=read_audio(file))\n",
        "\n",
        "    return upload_response.json().get('upload_url')\n",
        "\n",
        "# Metoda transcribe()przyjmuje jako argument upload_url i tworzy żądanie POST w celu uzyskania unikalnego identyfikatora transcription_id dla naszego żądania.\n",
        "def transcribe(upload_url): \n",
        "\n",
        "    json = {\"audio_url\": upload_url, \"auto_chapters\": True}\n",
        "    \n",
        "    response = requests.post(transcription_endpoint, json=json, headers=headers)\n",
        "    transcription_id = response.json()['id']\n",
        "\n",
        "    return transcription_id\n",
        "\n",
        "#Aby zobaczyć wynik transkrypcji, należy stworzyć żądanie GET dla serwerów AssemblyAI. \n",
        "#Aby poznać status żądania, należy podać unikalny identyfikator (transcription_id). \n",
        "\n",
        "def get_result(transcription_id): \n",
        "\n",
        "    current_status = \"queued\"\n",
        "\n",
        "    endpoint = f\"https://api.assemblyai.com/v2/transcript/{transcription_id}\"\n",
        "\n",
        "    while current_status not in (\"completed\", \"error\"):\n",
        "        \n",
        "        response = requests.get(endpoint, headers=headers)\n",
        "        current_status = response.json()['status']\n",
        "        \n",
        "        if current_status in (\"completed\", \"error\"):\n",
        "            return response.json()\n",
        "        else:\n",
        "            sleep(10)\n",
        "\n",
        "# Wykonanie żądania\n",
        "upload_url = upload(\"cooper.flac\")\n",
        "\n",
        "transcription_id = transcribe(upload_url)\n",
        "\n",
        "response = get_result(transcription_id)\n",
        "\n",
        "response\n",
        "\n",
        "print(response[\"text\"])"
      ],
      "metadata": {
        "id": "ZcYQ1BMLLjM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"OSINT-7.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Ocena czytelności tekstu, https://pypi.org/project/textatistic/\n",
        "\n",
        "!pip install textatistic\n",
        "\n",
        "import textatistic\n",
        "\n",
        "from textatistic import Textatistic # Zainicjowanie obiektu Textatistic\n",
        "\n",
        "tekst = (\"Well, I think storytelling isn't is evolving. The idea of what that even means. We tell a story in a different way than we did, maybe in an oral tradition. Only I think people probably said that about this. The idea of talkies as opposed to a silent film, is it going to be ruined, you know? But I think this the dawn of virtual reality or augmented reality in an experience of a story of cinema, I think is wonderfully exciting.\")\n",
        "\n",
        "Textatistic(text).flesch_score"
      ],
      "metadata": {
        "id": "O1NcTDrIPr7b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}